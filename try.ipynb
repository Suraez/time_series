{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requests</th>\n",
       "      <th>memory</th>\n",
       "      <th>cpu</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2023-10-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2023-10-01 00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2023-10-01 00:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2023-10-01 00:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2023-10-01 00:04:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   requests  memory    cpu           timestamp\n",
       "0       6.0   0.105  0.003 2023-10-01 00:00:00\n",
       "1      29.0   0.104  0.004 2023-10-01 00:01:00\n",
       "2      12.0   0.105  0.003 2023-10-01 00:02:00\n",
       "3      18.0   0.105  0.004 2023-10-01 00:03:00\n",
       "4       4.0   0.105  0.003 2023-10-01 00:04:00"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"preprocessed_dataset.csv\", parse_dates=[\"timestamp\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_dataset.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "# Ensure data is sorted by timestamp\n",
    "df = df.sort_values(by=\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# Select relevant columns\n",
    "target_col = \"requests\"\n",
    "feature_cols = [\"memory\", \"cpu\"]\n",
    "\n",
    "# Normalize features\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "df[feature_cols] = scaler_x.fit_transform(df[feature_cols])\n",
    "df[target_col] = scaler_y.fit_transform(df[[target_col]])\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "data = df[[\"requests\", \"memory\", \"cpu\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, input_len=12, pred_len=12):  # Increased input_len to avoid lag errors\n",
    "        self.data = data\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.input_len - self.pred_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        past_values = self.data[index : index + self.input_len]\n",
    "        future_values = self.data[index + self.input_len : index + self.input_len + self.pred_len]\n",
    "        \n",
    "        # Create a binary mask (1 for observed values)\n",
    "        past_observed_mask = np.ones_like(past_values)\n",
    "\n",
    "        # Extract time features (e.g., normalized time step indices)\n",
    "        past_time_features = np.expand_dims(np.arange(self.input_len) / self.input_len, axis=1)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(past_values, dtype=torch.float32),\n",
    "            torch.tensor(past_time_features, dtype=torch.float32),\n",
    "            torch.tensor(past_observed_mask, dtype=torch.float32),\n",
    "            torch.tensor(future_values, dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequence lengths\n",
    "input_len = 24  # Increased to avoid lag-related errors\n",
    "pred_len = 12   # Forecasting 12 time steps ahead\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "dataset = TimeSeriesDataset(data, input_len, pred_len)\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1404"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch length: 4\n",
      "past_values shape: torch.Size([16, 112, 3])\n",
      "past_time_features shape: torch.Size([16, 112, 1])\n",
      "past_observed_mask shape: torch.Size([16, 112, 3])\n",
      "future_values shape: torch.Size([16, 12, 3])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(f\"Batch length: {len(batch)}\")  # Should print 4\n",
    "    print(f\"past_values shape: {batch[0].shape}\")  # (batch_size, input_len, features)\n",
    "    print(f\"past_time_features shape: {batch[1].shape}\")  \n",
    "    print(f\"past_observed_mask shape: {batch[2].shape}\")  \n",
    "    print(f\"future_values shape: {batch[3].shape}\")  \n",
    "    break  # Only print once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoformerConfig, AutoformerModel\n",
    "\n",
    "# Define model configuration\n",
    "config = AutoformerConfig(\n",
    "    prediction_length=pred_len,\n",
    "    context_length=input_len,  \n",
    "    input_size=len(feature_cols),  \n",
    "    lags_sequence=[1, 2, 3, 4],  # Manually define lags (must be <= context_length)\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = AutoformerModel(config).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x788f9c257ae0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask:  torch.Size([16, 112, 3])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "lags cannot go further than history length, found lag 4 while history length is only 112",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m optimizer.zero_grad()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Forward pass (passing correct inputs)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_values\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.last_hidden_state  \u001b[38;5;66;03m# Extract predictions\u001b[39;00m\n\u001b[32m     24\u001b[39m loss = criterion(outputs, y)\n\u001b[32m     25\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:1660\u001b[39m, in \u001b[36mAutoformerModel.forward\u001b[39m\u001b[34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[39m\n\u001b[32m   1657\u001b[39m use_cache = use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_cache\n\u001b[32m   1658\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1660\u001b[39m transformer_inputs, temporal_features, loc, scale, static_feat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_network_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1670\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1671\u001b[39m     enc_input = torch.cat(\n\u001b[32m   1672\u001b[39m         (\n\u001b[32m   1673\u001b[39m             transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m.config.context_length, ...],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1676\u001b[39m         dim=-\u001b[32m1\u001b[39m,\n\u001b[32m   1677\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:1585\u001b[39m, in \u001b[36mAutoformerModel.create_network_inputs\u001b[39m\u001b[34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[39m\n\u001b[32m   1579\u001b[39m \u001b[38;5;66;03m# lagged features\u001b[39;00m\n\u001b[32m   1580\u001b[39m subsequences_length = (\n\u001b[32m   1581\u001b[39m     \u001b[38;5;28mself\u001b[39m.config.context_length + \u001b[38;5;28mself\u001b[39m.config.prediction_length\n\u001b[32m   1582\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1583\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.context_length\n\u001b[32m   1584\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1585\u001b[39m lagged_sequence = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_lagged_subsequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsequences_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubsequences_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1586\u001b[39m lags_shape = lagged_sequence.shape\n\u001b[32m   1587\u001b[39m reshaped_lagged_sequence = lagged_sequence.reshape(lags_shape[\u001b[32m0\u001b[39m], lags_shape[\u001b[32m1\u001b[39m], -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/transformers/models/autoformer/modeling_autoformer.py:1480\u001b[39m, in \u001b[36mAutoformerModel.get_lagged_subsequences\u001b[39m\u001b[34m(self, sequence, subsequences_length, shift)\u001b[39m\n\u001b[32m   1478\u001b[39m sequence_length = sequence.shape[\u001b[32m1\u001b[39m]\n\u001b[32m   1479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(indices) + subsequences_length > sequence_length:\n\u001b[32m-> \u001b[39m\u001b[32m1480\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1481\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlags cannot go further than history length, found lag \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1482\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile history length is only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1483\u001b[39m     )\n\u001b[32m   1485\u001b[39m \u001b[38;5;66;03m# extracts the lagged subsequences from the input sequence using the calculated indices\u001b[39;00m\n\u001b[32m   1486\u001b[39m lagged_values = []\n",
      "\u001b[31mValueError\u001b[39m: lags cannot go further than history length, found lag 4 while history length is only 112"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for past_values, past_time_features, past_observed_mask, future_values in train_loader:\n",
    "        past_time_features, past_observed_mask, past_values = (\n",
    "            past_time_features.to(device),\n",
    "            past_observed_mask.to(device),\n",
    "            past_values.to(device),\n",
    "        )\n",
    "\n",
    "        # print(past_time_features.shape)\n",
    "        print(\"mask: \", past_observed_mask.shape)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass (passing correct inputs)\n",
    "        outputs = model(\n",
    "            past_time_features=past_time_features,\n",
    "            past_observed_mask=past_observed_mask,\n",
    "            past_values=past_values\n",
    "        ).last_hidden_state  # Extract predictions\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from transformers import AutoformerConfig, AutoformerForPrediction, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_dataset.csv\")\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "input_features = ['memory', 'cpu']\n",
    "target_feature = 'requests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[input_features + [target_feature]] = scaler.fit_transform(df[input_features + [target_feature]])\n",
    "\n",
    "input_length = 48  # Past 48 time steps for input\n",
    "prediction_length = 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, input_length, prediction_length):\n",
    "        self.data = df\n",
    "        self.input_length = input_length\n",
    "        self.prediction_length = prediction_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.input_length - self.prediction_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        past_values = self.data.loc[idx : idx + self.input_length, target_feature].values\n",
    "        future_values = self.data.loc[idx + self.input_length : idx + self.input_length + self.prediction_length, target_feature].values\n",
    "        past_time_features = self.data.loc[idx : idx + self.input_length, input_features].values.reshape(self.input_length, -1)\n",
    "        future_time_features = self.data.loc[idx + self.input_length : idx + self.input_length + self.prediction_length, input_features].values.reshape(self.prediction_length, -1)\n",
    "        past_observed_mask = np.ones_like(past_values)  # Assume all values are observed\n",
    "        future_observed_mask = np.ones_like(future_values)  # Ensure correct shape\n",
    "        static_real_features = np.zeros((1, 1))  # Ensure shape is (1,)\n",
    "        static_categorical_features = np.zeros((1, 1))  # Added static categorical features\n",
    "\n",
    "        return {\n",
    "            \"past_values\": torch.tensor(past_values, dtype=torch.float32).unsqueeze(-1),  # Shape (61, 1)\n",
    "            \"future_values\": torch.tensor(future_values, dtype=torch.float32).unsqueeze(-1),  # Shape (24, 1)\n",
    "            \"past_time_features\": self.data.loc[idx : idx + self.input_length, input_features].values.reshape(-1, 124),  # Example adjustment\n",
    "            \"future_time_features\": torch.tensor(future_time_features, dtype=torch.float32).unsqueeze(1),  # Shape (24, 2)\n",
    "            \"past_observed_mask\": torch.tensor(past_observed_mask, dtype=torch.float32).unsqueeze(-1),  # Shape (61, 1)\n",
    "            \"future_observed_mask\": torch.tensor(future_observed_mask, dtype=torch.float32).unsqueeze(-1),  # Shape (24, 1)\n",
    "            \"static_real_features\": torch.tensor(static_real_features, dtype=torch.float32).expand(1, 1),  # Shape (1, 1)\n",
    "            \"static_categorical_features\": torch.tensor(static_categorical_features, dtype=torch.float32).expand(1, 1),  # Shape (1, 1)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = TimeSeriesDataset(df, input_length, prediction_length)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 124 into shape (61,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sample = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Fetch first sample\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(sample.items()):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mTimeSeriesDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     12\u001b[39m past_values = \u001b[38;5;28mself\u001b[39m.data.loc[idx : idx + \u001b[38;5;28mself\u001b[39m.input_length, target_feature].values\n\u001b[32m     13\u001b[39m future_values = \u001b[38;5;28mself\u001b[39m.data.loc[idx + \u001b[38;5;28mself\u001b[39m.input_length : idx + \u001b[38;5;28mself\u001b[39m.input_length + \u001b[38;5;28mself\u001b[39m.prediction_length, target_feature].values\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m past_time_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m future_time_features = \u001b[38;5;28mself\u001b[39m.data.loc[idx + \u001b[38;5;28mself\u001b[39m.input_length : idx + \u001b[38;5;28mself\u001b[39m.input_length + \u001b[38;5;28mself\u001b[39m.prediction_length, input_features].values.reshape(\u001b[38;5;28mself\u001b[39m.prediction_length, -\u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m past_observed_mask = np.ones_like(past_values)  \u001b[38;5;66;03m# Assume all values are observed\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: cannot reshape array of size 124 into shape (61,newaxis)"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]  # Fetch first sample\n",
    "for key, value in sorted(sample.items()):\n",
    "    print(f\"{key}  {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Autoformer model\n",
    "config = AutoformerConfig(\n",
    "    context_length=input_length,\n",
    "    prediction_length=prediction_length,\n",
    "    input_size=len(input_features),\n",
    "    target_size=1\n",
    ")\n",
    "model = AutoformerForPrediction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=64,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 124 into shape (61,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/transformers/trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/transformers/trainer.py:2500\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2498\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2499\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2500\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2501\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2502\u001b[39m     step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/transformers/trainer.py:5180\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches)\u001b[39m\n\u001b[32m   5178\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5179\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5180\u001b[39m         batch_samples += [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m   5181\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5182\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/accelerate/data_loader.py:564\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     current_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mTimeSeriesDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     12\u001b[39m past_values = \u001b[38;5;28mself\u001b[39m.data.loc[idx : idx + \u001b[38;5;28mself\u001b[39m.input_length, target_feature].values\n\u001b[32m     13\u001b[39m future_values = \u001b[38;5;28mself\u001b[39m.data.loc[idx + \u001b[38;5;28mself\u001b[39m.input_length : idx + \u001b[38;5;28mself\u001b[39m.input_length + \u001b[38;5;28mself\u001b[39m.prediction_length, target_feature].values\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m past_time_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m future_time_features = \u001b[38;5;28mself\u001b[39m.data.loc[idx + \u001b[38;5;28mself\u001b[39m.input_length : idx + \u001b[38;5;28mself\u001b[39m.input_length + \u001b[38;5;28mself\u001b[39m.prediction_length, input_features].values.reshape(\u001b[38;5;28mself\u001b[39m.prediction_length, -\u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m past_observed_mask = np.ones_like(past_values)  \u001b[38;5;66;03m# Assume all values are observed\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: cannot reshape array of size 124 into shape (61,newaxis)"
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a43479da9040e390b49c9a0031f5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f295ab3ce23545f296b5a121c98d3b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/116k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e48d3fdee44e178173999126ad1cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/92.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoformerConfig, AutoformerForPrediction\n",
    "\n",
    "config = AutoformerConfig.from_pretrained(\"kashif/autoformer-traffic-hourly\")\n",
    "model = AutoformerForPrediction.from_pretrained(\"kashif/autoformer-traffic-hourly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "\n",
    "\n",
    "\n",
    "def create_backtest_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data)\n",
    "\n",
    "    # we create a Validation Instance splitter which will sample the very last\n",
    "    # context window seen during training only for the encoder.\n",
    "    instance_sampler = create_instance_splitter(config, \"validation\")\n",
    "\n",
    "    # we apply the transformations in train mode\n",
    "    testing_instances = instance_sampler.apply(transformed_data, is_train=True)\n",
    "\n",
    "    return as_stacked_batches(\n",
    "        testing_instances,\n",
    "        batch_size=batch_size,\n",
    "        output_type=torch.tensor,\n",
    "        field_names=PREDICTION_INPUT_NAMES,\n",
    "    )\n",
    "\n",
    "def create_test_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=False)\n",
    "\n",
    "    # We create a test Instance splitter to sample the very last\n",
    "    # context window from the dataset provided.\n",
    "    instance_sampler = create_instance_splitter(config, \"test\")\n",
    "\n",
    "    # We apply the transformations in test mode\n",
    "    testing_instances = instance_sampler.apply(transformed_data, is_train=False)\n",
    "    \n",
    "    return as_stacked_batches(\n",
    "        testing_instances,\n",
    "        batch_size=batch_size,\n",
    "        output_type=torch.tensor,\n",
    "        field_names=PREDICTION_INPUT_NAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoformerConfig {\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"AutoformerForPrediction\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"autocorrelation_factor\": 3,\n",
       "  \"cardinality\": [\n",
       "    0\n",
       "  ],\n",
       "  \"context_length\": 48,\n",
       "  \"d_model\": 16,\n",
       "  \"decoder_attention_heads\": 2,\n",
       "  \"decoder_ffn_dim\": 32,\n",
       "  \"decoder_layerdrop\": 0.1,\n",
       "  \"decoder_layers\": 2,\n",
       "  \"distribution_output\": \"student_t\",\n",
       "  \"dropout\": 0.1,\n",
       "  \"embedding_dimension\": [\n",
       "    0\n",
       "  ],\n",
       "  \"encoder_attention_heads\": 2,\n",
       "  \"encoder_ffn_dim\": 32,\n",
       "  \"encoder_layerdrop\": 0.1,\n",
       "  \"encoder_layers\": 2,\n",
       "  \"feature_size\": 47,\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_size\": 1,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label_length\": 10,\n",
       "  \"lags_sequence\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    167,\n",
       "    168,\n",
       "    169,\n",
       "    335,\n",
       "    336,\n",
       "    337,\n",
       "    503,\n",
       "    504,\n",
       "    505,\n",
       "    671,\n",
       "    672,\n",
       "    673,\n",
       "    719,\n",
       "    720,\n",
       "    721\n",
       "  ],\n",
       "  \"loss\": \"nll\",\n",
       "  \"model_type\": \"autoformer\",\n",
       "  \"moving_average\": 25,\n",
       "  \"num_dynamic_real_features\": 0,\n",
       "  \"num_parallel_samples\": 100,\n",
       "  \"num_static_categorical_features\": 0,\n",
       "  \"num_static_real_features\": 0,\n",
       "  \"num_time_features\": 5,\n",
       "  \"prediction_length\": 24,\n",
       "  \"scaling\": \"mean\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.49.0\",\n",
       "  \"use_cache\": true\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_backtest_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_dataloader = \u001b[43mcreate_backtest_dataloader\u001b[49m(\n\u001b[32m      2\u001b[39m     config=config,\n\u001b[32m      3\u001b[39m     freq=freq,\n\u001b[32m      4\u001b[39m     data=test_dataset,\n\u001b[32m      5\u001b[39m     batch_size=\u001b[32m64\u001b[39m,\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'create_backtest_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataloader = create_backtest_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=test_dataset,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of AutoformerModel(\n",
       "  (scaler): AutoformerMeanScaler()\n",
       "  (encoder): AutoformerEncoder(\n",
       "    (value_embedding): AutoformerValueEmbedding(\n",
       "      (value_projection): Linear(in_features=18, out_features=64, bias=False)\n",
       "    )\n",
       "    (embed_positions): AutoformerSinusoidalPositionalEmbedding(48, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x AutoformerEncoderLayer(\n",
       "        (self_attn): AutoformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (final_layer_norm): AutoformerLayernorm(\n",
       "          (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decomp1): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "        (decomp2): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): AutoformerDecoder(\n",
       "    (value_embedding): AutoformerValueEmbedding(\n",
       "      (value_projection): Linear(in_features=18, out_features=64, bias=False)\n",
       "    )\n",
       "    (embed_positions): AutoformerSinusoidalPositionalEmbedding(48, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x AutoformerDecoderLayer(\n",
       "        (self_attn): AutoformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): AutoformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (final_layer_norm): AutoformerLayernorm(\n",
       "          (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decomp1): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "        (decomp2): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "        (decomp3): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "        (trend_projection): Conv1d(64, 18, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (seasonality_projection): Linear(in_features=64, out_features=18, bias=True)\n",
       "  )\n",
       "  (decomposition_layer): AutoformerSeriesDecompositionLayer(\n",
       "    (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoformerConfig, AutoformerModel\n",
    "\n",
    "# Initializing a default Autoformer configuration\n",
    "\n",
    "config = AutoformerConfig(prediction_length=24, input_size=2)\n",
    "\n",
    "model = AutoformerModel(config)\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "df['requests'] = df['requests'].fillna(0)\n",
    "df['time_idx'] = df['datetime'].astype('int64') // 10**9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requests</th>\n",
       "      <th>memory</th>\n",
       "      <th>cpu</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2023-10-01 00:00:00</td>\n",
       "      <td>2023-10-01 00:00:00</td>\n",
       "      <td>1696118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2023-10-01 00:01:00</td>\n",
       "      <td>2023-10-01 00:01:00</td>\n",
       "      <td>1696118460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2023-10-01 00:02:00</td>\n",
       "      <td>2023-10-01 00:02:00</td>\n",
       "      <td>1696118520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2023-10-01 00:03:00</td>\n",
       "      <td>2023-10-01 00:03:00</td>\n",
       "      <td>1696118580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2023-10-01 00:04:00</td>\n",
       "      <td>2023-10-01 00:04:00</td>\n",
       "      <td>1696118640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   requests  memory    cpu            timestamp            datetime  \\\n",
       "0       6.0   0.105  0.003  2023-10-01 00:00:00 2023-10-01 00:00:00   \n",
       "1      29.0   0.104  0.004  2023-10-01 00:01:00 2023-10-01 00:01:00   \n",
       "2      12.0   0.105  0.003  2023-10-01 00:02:00 2023-10-01 00:02:00   \n",
       "3      18.0   0.105  0.004  2023-10-01 00:03:00 2023-10-01 00:03:00   \n",
       "4       4.0   0.105  0.003  2023-10-01 00:04:00 2023-10-01 00:04:00   \n",
       "\n",
       "     time_idx  \n",
       "0  1696118400  \n",
       "1  1696118460  \n",
       "2  1696118520  \n",
       "3  1696118580  \n",
       "4  1696118640  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unknown category 'nan' encountered. Set `add_nan=True` to allow unknown categories\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/pytorch_forecasting/data/encoders.py:416\u001b[39m, in \u001b[36mNaNLabelEncoder.transform\u001b[39m\u001b[34m(self, y, return_norm, target_scale, ignore_na)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     encoded = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyError\u001b[39m: nan",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesDataSet\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset = \u001b[43mTimeSeriesDataSet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime_idx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrequests\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmemory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/pytorch_forecasting/data/timeseries.py:626\u001b[39m, in \u001b[36mTimeSeriesDataSet.__init__\u001b[39m\u001b[34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[39m\n\u001b[32m    623\u001b[39m data = data.sort_values(\u001b[38;5;28mself\u001b[39m.group_ids + [\u001b[38;5;28mself\u001b[39m.time_idx])\n\u001b[32m    625\u001b[39m \u001b[38;5;66;03m# preprocess data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mTarget normalizer is separate and not in scalers.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_names:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/pytorch_forecasting/data/timeseries.py:1093\u001b[39m, in \u001b[36mTimeSeriesDataSet._preprocess_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1087\u001b[39m     encoder = deepcopy(\n\u001b[32m   1088\u001b[39m         \u001b[38;5;28mself\u001b[39m._categorical_encoders.get(group_name, NaNLabelEncoder())\n\u001b[32m   1089\u001b[39m     )\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28mself\u001b[39m._categorical_encoders[group_name] = encoder.fit(\n\u001b[32m   1091\u001b[39m         data[name].to_numpy().reshape(-\u001b[32m1\u001b[39m), overwrite=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1092\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     data[group_name] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m   1095\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;66;03m# encode categoricals first to ensure\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[38;5;66;03m# that group normalizer relies on encoded categories\u001b[39;00m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   1100\u001b[39m     \u001b[38;5;28mself\u001b[39m.target_normalizer, (GroupNormalizer, MultiNormalizer)\n\u001b[32m   1101\u001b[39m ):  \u001b[38;5;66;03m# if we use a group normalizer, group_ids must be encoded as well\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/pytorch_forecasting/data/timeseries.py:1390\u001b[39m, in \u001b[36mTimeSeriesDataSet.transform_values\u001b[39m\u001b[34m(self, name, values, data, inverse, group_id, **kwargs)\u001b[39m\n\u001b[32m   1388\u001b[39m \u001b[38;5;66;03m# remaining categories\u001b[39;00m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.flat_categoricals + \u001b[38;5;28mself\u001b[39m.group_ids + \u001b[38;5;28mself\u001b[39m._group_ids:\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[38;5;66;03m# reals\u001b[39;00m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reals:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/pytorch_forecasting/data/encoders.py:418\u001b[39m, in \u001b[36mNaNLabelEncoder.transform\u001b[39m\u001b[34m(self, y, return_norm, target_scale, ignore_na)\u001b[39m\n\u001b[32m    416\u001b[39m             encoded = [\u001b[38;5;28mself\u001b[39m.classes_[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[32m    417\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    419\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown category \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.args[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m encountered. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    420\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mSet `add_nan=True` to allow unknown categories\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m             )\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, torch.Tensor):\n\u001b[32m    424\u001b[39m     encoded = torch.tensor(encoded, dtype=torch.long, device=y.device)\n",
      "\u001b[31mKeyError\u001b[39m: \"Unknown category 'nan' encountered. Set `add_nan=True` to allow unknown categories\""
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "dataset = TimeSeriesDataSet(data=df, time_idx='time_idx', target='requests', group_ids=['memory', 'cpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Timeseries index should be of type integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m model = AutoformerModel(config)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Set up the dataset and dataloader\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m dataset = \u001b[43mTimeSeriesDataSet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrequests\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmemory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m dataloader = DataLoader(dataset, batch_size=\u001b[32m32\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Define the loss function and optimizer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/pytorch_forecasting/data/timeseries.py:609\u001b[39m, in \u001b[36mTimeSeriesDataSet.__init__\u001b[39m\u001b[34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[39m\n\u001b[32m    604\u001b[39m     data.loc[:, \u001b[33m\"\u001b[39m\u001b[33mencoder_length\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m    605\u001b[39m         \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# dummy - real value will be set dynamically in __getitem__()\u001b[39;00m\n\u001b[32m    606\u001b[39m     )\n\u001b[32m    608\u001b[39m \u001b[38;5;66;03m# validate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[38;5;66;03m# add lags\u001b[39;00m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._lags) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/publish/newenv/lib/python3.12/site-packages/pytorch_forecasting/data/timeseries.py:998\u001b[39m, in \u001b[36mTimeSeriesDataSet._validate_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    995\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: pd.DataFrame):\n\u001b[32m    996\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate assumptions on data..\"\"\"\u001b[39;00m\n\u001b[32m    997\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m         data[\u001b[38;5;28mself\u001b[39m.time_idx].dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mi\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    999\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33mTimeseries index should be of type integer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1000\u001b[39m     \u001b[38;5;66;03m# numeric categoricals which can cause issues in tensorborad logging\u001b[39;00m\n\u001b[32m   1001\u001b[39m     category_columns = data.head(\u001b[32m1\u001b[39m).select_dtypes(\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m).columns\n",
      "\u001b[31mAssertionError\u001b[39m: Timeseries index should be of type integer"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoformerConfig, AutoformerModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "\n",
    "# Define the model configuration\n",
    "config = AutoformerConfig(\n",
    "    prediction_length=24,  # Set your prediction length\n",
    "    input_features=2\n",
    ")\n",
    "\n",
    "# Initialize the model with the configuration\n",
    "model = AutoformerModel(config)\n",
    "\n",
    "# Set up the dataset and dataloader\n",
    "dataset = TimeSeriesDataSet(data=df, time_idx='timestamp', target='requests', group_ids=['memory', 'cpu'])\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()  # Clear the previous gradients\n",
    "        \n",
    "        # Get the inputs and targets from the batch\n",
    "        past_values = batch[\"past_values\"].squeeze(-1)  # Remove extra dimensions\n",
    "        future_values = batch[\"future_values\"].squeeze(-1)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(past_values)  # Assuming the model takes past values and outputs predictions\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, future_values)\n",
    "        loss.backward()  # Backpropagate the loss\n",
    "        \n",
    "        optimizer.step()  # Update the model parameters\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader)}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'autoformer_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
