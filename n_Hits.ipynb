{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a7081e",
   "metadata": {},
   "source": [
    "### N-Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eff9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj-desk/projects/time_series/env/lib/python3.12/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n",
      "/home/suraj-desk/projects/time_series/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel, TCNModel  # You can try other models like TFTModel, TransformerModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "from darts.models import NHiTSModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27d65dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_445153/3835831487.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill', axis=1).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"preprocessed_dataset.csv\", parse_dates=[\"timestamp\"])\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "df = df.fillna(method='ffill', axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d41d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data (optional but recommended)\n",
    "scaler_target = Scaler(MinMaxScaler())\n",
    "scaler_covariates = Scaler(MinMaxScaler())\n",
    "\n",
    "# Convert to Darts TimeSeries\n",
    "series_target = TimeSeries.from_dataframe(df, value_cols=[\"requests\"]).astype(np.float32)\n",
    "series_covariates = TimeSeries.from_dataframe(df, value_cols=[\"memory\", \"cpu\"]).astype(np.float32)\n",
    "\n",
    "# Normalize\n",
    "series_target = scaler_target.fit_transform(series_target)\n",
    "series_covariates = scaler_covariates.fit_transform(series_covariates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f4e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train-test split\n",
    "train_size = 0.8  # 80% training, 20% testing\n",
    "train_target, test_target = series_target.split_after(train_size)\n",
    "train_covariates, test_covariates = series_covariates.split_after(train_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81ec064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 2, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_covariates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c500ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 11\n",
    "prediction_length = 2 # one step forecast\n",
    "eps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f82524",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=6,\n",
    "    output_chunk_length=6,\n",
    "    num_blocks=2,\n",
    "    n_epochs=5,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2233d3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A2000 12GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.7 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "9.2 K     Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.833     Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 180/180 [00:04<00:00, 38.12it/s, train_loss=0.000121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 180/180 [00:04<00:00, 38.10it/s, train_loss=0.000121]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NHiTSModel(output_chunk_shift=0, num_stacks=3, num_blocks=2, num_layers=2, layer_widths=512, pooling_kernel_sizes=None, n_freq_downsample=None, dropout=0.1, activation=ReLU, MaxPool1d=True, input_chunk_length=6, output_chunk_length=6, n_epochs=5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_target, past_covariates=train_covariates, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082ecbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "test_covariates_extended = series_covariates[-(len(test_target) + model.input_chunk_length):]\n",
    "\n",
    "#nHiTS model predcition\n",
    "nhits_pred_series = model.predict(n=len(test_target),past_covariates=test_covariates_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60d022e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhits_pred_original = scaler_target.inverse_transform(nhits_pred_series)\n",
    "test_target_original = scaler_target.inverse_transform(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "896ed756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics import mse, rmse, mae, r2_score, mape\n",
    "\n",
    "def evaluate_forecast(true_series, pred_series):\n",
    "    results = {\n",
    "        \"MSE\": mse(true_series, pred_series),\n",
    "        \"RMSE\": rmse(true_series, pred_series),\n",
    "        \"MAE\": mae(true_series, pred_series),\n",
    "        \"MAPE\": mape(true_series, pred_series),\n",
    "        \"R2\": r2_score(true_series, pred_series)\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4261fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_forecast(test_target_original, nhits_pred_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bed50744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': np.float32(157703.67),\n",
       " 'RMSE': np.float32(397.1192),\n",
       " 'MAE': np.float32(135.73431),\n",
       " 'MAPE': np.float32(388.96042),\n",
       " 'R2': np.float32(-0.012715459)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b34dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
